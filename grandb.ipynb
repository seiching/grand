{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "sentence = \"一氧硫二全球暖化三反聖嬰現像是核能電廠排放廢水\"\n",
    "#print (\"Input：\", sentence)\n",
    "words = jieba.cut(sentence, cut_all=False)\n",
    "print (\"Output 精確模式 False Mode：\")\n",
    "for word in words:\n",
    "    print(word)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "\n",
    "str_text = \"一氧硫二全球暖化三反聖嬰現像是核能電廠排放廢水\"\n",
    "#print (\"Input：\", sentence)\n",
    "#words = jieba.cut(sentence, cut_all=False)\n",
    "str_soso1=jieba.cut_for_search(str_text)\n",
    "print (\"Output 精確模式 False Mode：\")\n",
    "for word in str_soso1:\n",
    "    print(word)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "str_text = \"一氧硫二全球暖化三反聖嬰現像是核能電廠排放廢水\"\n",
    "a=jieba.analyse.textrank(sentence) \n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?jieba.analyse.textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in test:\n",
    "    :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba  \n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('grand.db')\n",
    "sql=\"SELECT filename, sentence FROM Bpart;\"\n",
    "pdgrand=pd.read_sql(sql,conn)\n",
    "for i in range(len(pdgrand)):\n",
    "   filename=pdgrand.filename.values[i]\n",
    "   sentence=pdgrand.sentence.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Bcut (filename, cut) VALUES('%s', '%s')\"  %(filename, cut)\n",
    "     conn.execute(sql )\n",
    " \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba  \n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('grand.db')\n",
    "sql=\"SELECT filename, sentence FROM Apart;\"\n",
    "pdgrand=pd.read_sql(sql,conn)\n",
    "for i in range(len(pdgrand)):\n",
    "   filename=pdgrand.filename.values[i]\n",
    "   sentence=pdgrand.sentence.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Acut (filename, cut) VALUES('%s', '%s')\"  %(filename, cut)\n",
    "     conn.execute(sql )\n",
    " \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"insert into Ccut (filename, cut) VALUES('%s', '%s', %d)\"  % ('test', 'cut',1)\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba  \n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('grand.db')\n",
    "sql=\"SELECT filename, sentence,Q1,Q2,Q3,Q4 FROM Cpart;\"\n",
    "pdgrand=pd.read_sql(sql,conn)\n",
    "for i in range(len(pdgrand)):\n",
    "   filename=pdgrand.filename.values[i]\n",
    "   #q1\n",
    "   sentence=pdgrand.Q1.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Ccut (filename, cut,qno) VALUES('%s', '%s',%d )\"  %(filename, cut,1)\n",
    "     conn.execute(sql )\n",
    "   sentence=pdgrand.Q2.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Ccut (filename, cut,qno) VALUES('%s', '%s',%d )\"  %(filename, cut,2)\n",
    "     conn.execute(sql )\n",
    "   sentence=pdgrand.Q3.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Ccut (filename, cut,qno) VALUES('%s', '%s',%d )\"  %(filename, cut,3)\n",
    "     conn.execute(sql ) \n",
    "   sentence=pdgrand.Q4.values[i]\n",
    "   #print(station)      \n",
    "   words = jieba.cut(sentence, cut_all=False)\n",
    "   for cut in words:\n",
    "     sql=\"insert into Ccut (filename, cut,qno) VALUES('%s', '%s',%d )\"  %(filename, cut,4)\n",
    "     conn.execute(sql ) \n",
    " \n",
    "\n",
    "conn.commit()\n",
    "\n",
    "conn.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(\"一氧化碳二氧氣3一氧化碳是氮氣\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba  \n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def findq4pos(str,q4,percent):\n",
    "   pos4trystart=int(len(str)*percent)\n",
    "   q4try=str[pos4trystart:]\n",
    "   po4start=q4try.find(q4) \n",
    "   if (po4start<0):\n",
    "     return -1,q4try\n",
    "   q4=str[pos4trystart+q4try.find(st)+1:]\n",
    "   return po4start, pos4trystart,q4\n",
    "def findq4pos(str,q4,percent):\n",
    "   pos4trystart=int(len(str)*percent)\n",
    "   q4try=str[pos4trystart:]\n",
    "   po4start=q4try.find(q4) \n",
    "   #print('q4try',q4try,'start=',po4start)\n",
    "   if (po4start<0):\n",
    "     return -1,pos4trystart,q4try\n",
    "   q4=str[pos4trystart+po4start+1:]\n",
    "   return po4start, pos4trystart,q4\n",
    "def findq4(str,q4possible):\n",
    "  for st in q4possible:\n",
    "    po4start, pos4trystart,q4= findq4pos(str,st,0.6)\n",
    "    if (po4start!=-1):\n",
    "        break\n",
    "  if( po4start==-1):\n",
    "     # print('not found')\n",
    "      #nfound=nfound+1\n",
    "      position4=int(len(sentence)*0.75)\n",
    "  else:\n",
    "      position4= po4start+pos4trystart\n",
    "  return position4,q4,po4start\n",
    "\n",
    "def findq2pos(str,q2,pos2start,percent):\n",
    "   pos2tryend=int(len(str)*percent)\n",
    "   q2try=str[pos2start:pos2tryend]\n",
    "   #print('q2try',q2try)\n",
    "   po2start=q2try.find(q2) \n",
    "   #print('po2start',po2start)\n",
    "   #if(po2start==-1):\n",
    "      #print('not found q2try',q2try) \n",
    "   return po2start\n",
    "def findq3pos(str,q3,pos3start,pos4start):\n",
    "   #pos2tryend=int(len(str)*percent)\n",
    "  # q3='三'\n",
    "   pos3end=pos4start-1\n",
    "   q3try=str[pos3start:pos3end]\n",
    "   #print('q3=',q3,'q3try',q3try)\n",
    "   po3start=q3try.find(q3) \n",
    "   #print('po2start',pos3start)\n",
    "   #if(po3start==-1):\n",
    "      #print('q3try',q3try) \n",
    "   return po3start\n",
    "\n",
    "conn = sqlite3.connect('grand.db')\n",
    "sql=\"SELECT filename, sentence,position4 FROM Cpart;\"\n",
    "pdgrand=pd.read_sql(sql,conn)\n",
    "q4=\"\"\n",
    "qrtry=\"\"\n",
    "q4possible=['是','4','市','式','四','是','世','室','事','試','士','似','適','示','伺','寺','釋']  \n",
    "q2possible=['2','二']\n",
    "q3possible=['山','3','三','參']\n",
    "#for i in range(len(pdgrand)):\n",
    "nfound=0\n",
    "for i in range(len(pdgrand)):\n",
    "#for i in range(100):\n",
    "  filename=pdgrand.filename.values[i]\n",
    "  q4notfound=0\n",
    "  sentence=pdgrand.sentence.values[i]\n",
    "  #sentence='1.5公里21點4公里山1.3公里是1.6公里 '\n",
    "  #position4=pdgrand.position4.values[i]\n",
    "  position4,q4,q4notfound=findq4(sentence,q4possible)  \n",
    "  if(q4notfound==-1):\n",
    "        nfound=nfound+1\n",
    "  q2startinit=2  \n",
    "  for st in q2possible:\n",
    "    position2= findq2pos(sentence,st,q2startinit,0.5)\n",
    "    if (position2!=-1):\n",
    "        break\n",
    "  if(position2==-1):\n",
    "     #print('not found')\n",
    "     nfound=nfound+1\n",
    "     position2=int(len(sentence)*0.25)\n",
    "  else:\n",
    "    position2=position2+q2startinit\n",
    "  #print('q2=',q2position)\n",
    "  q1=sentence[1:position2]\n",
    "  for st in q3possible:\n",
    "    position3=findq3pos(sentence,st, position2,position4)\n",
    "    #print('loopq3',position3,st,'len sentence=',len(sentence))\n",
    "    if (position3!=-1):\n",
    "          break\n",
    "  if(position3==-1):\n",
    "     #print('q3 not found')\n",
    "     nfound=nfound+1\n",
    "     position3=int(len(sentence)*0.5)\n",
    "  else:\n",
    "    position3=position3+position2+1\n",
    "  \n",
    "  q3=sentence[position3:position4]\n",
    "  #print('position3=',position3)\n",
    "  q2=sentence[position2+1:position3-1]\n",
    "  sql=\"update Cpart set Q1='%s',Q2='%s',Q3='%s',Q4='%s',position2=%d,position3=%d,position4=%d\\\n",
    "  where filename='%s' \"  %(q1,q2,q3,q4,position2,position3,position4,filename) \n",
    "  conn.execute(sql )\n",
    "  #print('sentence=',sentence,' q1=',q1,' q2=',q2,' q3=',q3,'q4=',q4)  \n",
    "conn.commit()\n",
    "conn.close() \n",
    "print('nfound=',nfound,'total=',len(pdgrand))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3possible='三'\n",
    "q3try='二全球暖化三反聖嬰現'\n",
    "\n",
    "po3start=q3try.find(q3possible)\n",
    "print(po3start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence= '1.5公里21點4公里山1.3公里是1.6公里'\n",
    "po2start=sentence.find('是') \n",
    "q4possible=['是','4','市','式','四','是','世','室','事','試','士','似','適','示','伺','寺','釋']  \n",
    "import pandas as pd\n",
    "def findq4pos(str,q4,percent):\n",
    "   pos4trystart=int(len(str)*percent)\n",
    "   q4try=str[pos4trystart:]\n",
    "   po4start=q4try.find(q4) \n",
    "   print('q4try',q4try,'start=',po4start)\n",
    "   if (po4start<0):\n",
    "     return -1,pos4trystart,q4try\n",
    "   q4=str[pos4trystart+po4start+1:]\n",
    "   return po4start, pos4trystart,q4\n",
    "def findq4(str,q4possible):\n",
    "  for st in q4possible:\n",
    "    po4start, pos4trystart,q4= findq4pos(str,st,0.6)\n",
    "    if (po4start!=-1):\n",
    "        break\n",
    "  if( po4start==-1):\n",
    "      print('not found')\n",
    "      nfound=nfound+1\n",
    "      position4=int(len(sentence)*0.75)\n",
    "  else:\n",
    "      position4= po4start+pos4trystart\n",
    "  return position4,q4\n",
    "\n",
    "position4,q4=findq4(sentence,q4possible)\n",
    "print('q4=',q4,'position4=',position4)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"1.5公里21點4公里山1.3公里是1.6公里\"\n",
    "str = \"Python is Object Oriented\"\n",
    "def findq4(str,q4,percent):\n",
    "   pos4trystart=int(len(str)*percent)\n",
    "   q4try=sentence[pos4start:]\n",
    "   po4start=q4try.find(str) \n",
    "   if (po4start<0):\n",
    "        return -1,q4try\n",
    "    \n",
    "   q4=sentence[pos4trystart+q4try.find(st)+1:]\n",
    "   return q4,q4try\n",
    "q4possible=['是','4','市','式','四','是','世','室','事','試','士','似','適','示','伺','寺','釋']   \n",
    "for st in q4possible:\n",
    "    q4= findq4(sentence,st,0.6)\n",
    "    if q4(<>-1 break\n",
    "    \n",
    "print(q4)\n",
    "#print(sentence.find(st))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('grand.db')\n",
    "sql=\"SELECT filename, sentence FROM Bpart;\"\n",
    "pdgrand=pd.read_sql(sql,conn)\n",
    "filename=pdgrand.filename.values[0]\n",
    "sentence=pdgrand.sentence.values[0]\n",
    "print(filename,sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"test\"\n",
    "cut=\"test\"\n",
    "sql=\"insert Bcut (filename, cut) VALUES('%s', '%s')\"  %(filename, cut)\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "from pathlib import Path\n",
    "r = speech_recognition.Recognizer()\n",
    "\n",
    "with speech_recognition.AudioFile(\"科技大擂台/grand/kaggle1/B/B0000001.wav\") as source:\n",
    "     audio = r.record(source)\n",
    "r.recognize_google(audio,language='zh-tw')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "directory = '科技大擂台/grand/kaggle1/B'  \n",
    "#directory = '科技大擂台/grand/kaggle1/test' # 要辨識的目錄\n",
    "import os\n",
    "import speech_recognition\n",
    "from pathlib import Path\n",
    "import jieba\n",
    "\n",
    "r = speech_recognition.Recognizer()\n",
    "objects = os.listdir(directory)  # find all objects in a dir\n",
    "result=[]\n",
    "for i in objects:  # check if very object in the folder ...\n",
    "    if os.path.isfile(os.path.join(directory, i)):  # ... is a file.\n",
    "      with speech_recognition.AudioFile(directory+\"/\"+i) as source:\n",
    "        audio = r.record(source)\n",
    "      result.append(r.recognize_google(audio,language='zh-tw')   )\n",
    "      print(result)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import jieba\n",
    "for sentence in result:\n",
    "    words = jieba.cut(sentence, cut_all=False)\n",
    "    for word in words:\n",
    "      print( word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "thefile = open('test2.txt', 'w', encoding = 'utf8')\n",
    "#objects = os.listdir(directory)  # find all objects in a dir\n",
    "ii=0\n",
    "for item in result:\n",
    "  thefile.write(\"%s\\n\" % (item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "directory = '科技大擂台/grand/kaggle1/B'  \n",
    "thefile = open('test3.txt', 'w', encoding = 'utf8')\n",
    "objects = os.listdir(directory)  # find all objects in a dir\n",
    "files=[]\n",
    "for i in objects:  # check if very object in the folder ...\n",
    "    if os.path.isfile(os.path.join(directory, i)):  # ... is a file.\n",
    "         thefile.write(\"%s\\n\" % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"select filename,sentence, substr(sentence,round(length(sentence)*0.6,-1),\\\n",
    "length(sentence)-round(length(sentence)*0.6,-1)+1) from Cpart  where  filename in  \\\n",
    "(SELECT  filename FROM Cpart where \\\n",
    "substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%4%' \\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%市%'  \\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%式%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%四%' \\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%是%'\\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%世%'\\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%室%'\\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%事%'\\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%試%'\\\n",
    "or  substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%式%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%士%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1)  like '%似%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1) like '%適%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1) like '%示%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1) like '%伺%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1) like '%寺%'\\\n",
    "or substr(sentence,round(length(sentence)*0.6,-1),length(sentence)-round(length(sentence)*0.6,-1)+1) like '%釋%'\\\n",
    ")\"\n",
    "print(sql)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
